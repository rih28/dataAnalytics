{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2cEVut4NFhXK/jrL9jVH1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rih28/dataAnalytics/blob/master/Tutorial4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-vuVzC7urdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# needed to create the data frame\n",
        "import pandas as pd\n",
        "\n",
        "# create data frame from csv file we hosted on our github\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/rih28/dataAnalytics/master/tutorial2dnndata.csv', index_col=0)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6saFKcySvM9c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c8a3e84c-508f-415a-e302-6a380033fa1b"
      },
      "source": [
        "# make sure we have our data by printing it out\n",
        "print(df[:6])\n",
        "# print(df) #all"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Apr  Aug  Dec  Feb  Jan  Jul  ...  Tue  Wed  year  temp  wdsp  NUM_TRIPS\n",
            "1    0    0    0    0    1    0  ...    0    0  2009  20.0   7.4   0.631126\n",
            "2    0    0    0    0    1    0  ...    0    0  2009  30.0  10.8   0.724951\n",
            "3    0    0    0    0    1    0  ...    1    0  2009  30.4   5.7   0.716044\n",
            "4    0    0    0    0    1    0  ...    0    0  2009  37.9  16.4   0.799994\n",
            "5    0    0    0    0    1    0  ...    0    0  2009  25.7  13.8   0.872611\n",
            "6    0    0    0    0    1    0  ...    0    0  2009  21.6   6.9   0.809792\n",
            "\n",
            "[6 rows x 23 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltGRAo1hvO8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "ae060356-4b17-42c9-d5a0-7e9d374e8b13"
      },
      "source": [
        "# needed to help with speedy maths based calculations\n",
        "import numpy as np\n",
        "\n",
        "# iloc allows us to select by rows. Here, we are shuffling the data by rows determined at random.\n",
        "shuffle = df.iloc[np.random.permutation(len(df))]\n",
        "\n",
        "# we are selecting all rows of the columns outliined i.e. The 3rd (2 as indexes start from 0)\n",
        "predictors = shuffle.iloc[:,0:22]\n",
        "# Since it is the last column, we can also use\n",
        "# predictorTest = shuffle.iloc[:,-1]\n",
        "\n",
        "# print out the first 6 rows of predictors.\n",
        "print(predictors[:6])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Sun  Thu  Tue  Wed  year  temp  wdsp\n",
            "558    0    0    0    0    0    0    0  ...    0    0    1    0  2010  68.1   9.8\n",
            "584    0    0    0    0    0    0    0  ...    0    1    0    0  2010  55.8   3.1\n",
            "135    0    0    0    0    0    0    0  ...    0    0    0    0  2009  60.6   6.8\n",
            "538    0    1    0    0    0    0    0  ...    0    0    0    0  2010  67.2   7.5\n",
            "268    0    0    0    0    0    0    0  ...    0    0    0    1  2009  42.9   7.3\n",
            "152    0    0    0    0    0    0    1  ...    0    0    0    0  2009  66.6   6.7\n",
            "\n",
            "[6 rows x 22 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL2F4qYEvbAK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3ef1f9f4-b625-4712-f96b-fa40096456c5"
      },
      "source": [
        "# print out the shuffled data (first 5 rows)\n",
        "shuffle[:5]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Apr</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Dec</th>\n",
              "      <th>Feb</th>\n",
              "      <th>Jan</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Jun</th>\n",
              "      <th>Mar</th>\n",
              "      <th>May</th>\n",
              "      <th>Nov</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>year</th>\n",
              "      <th>temp</th>\n",
              "      <th>wdsp</th>\n",
              "      <th>NUM_TRIPS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2010</td>\n",
              "      <td>68.1</td>\n",
              "      <td>9.8</td>\n",
              "      <td>0.723813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010</td>\n",
              "      <td>55.8</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0.822354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2009</td>\n",
              "      <td>60.6</td>\n",
              "      <td>6.8</td>\n",
              "      <td>0.676365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010</td>\n",
              "      <td>67.2</td>\n",
              "      <td>7.5</td>\n",
              "      <td>0.790915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2009</td>\n",
              "      <td>42.9</td>\n",
              "      <td>7.3</td>\n",
              "      <td>0.854527</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Apr  Aug  Dec  Feb  Jan  Jul  ...  Tue  Wed  year  temp  wdsp  NUM_TRIPS\n",
              "558    0    0    0    0    0    0  ...    1    0  2010  68.1   9.8   0.723813\n",
              "584    0    0    0    0    0    0  ...    0    0  2010  55.8   3.1   0.822354\n",
              "135    0    0    0    0    0    0  ...    0    0  2009  60.6   6.8   0.676365\n",
              "538    0    1    0    0    0    0  ...    0    0  2010  67.2   7.5   0.790915\n",
              "268    0    0    0    0    0    0  ...    0    1  2009  42.9   7.3   0.854527\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IezylO-rvgE3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "17c0668b-61fd-4c03-9a95-7c041eb8731e"
      },
      "source": [
        "# Select all rows for the 2nd column (i.e. 1)\n",
        "targets = shuffle.iloc[:,22]\n",
        "\n",
        "# print out the first 6 rows of the targets data.\n",
        "print(targets[:6])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "558    0.723813\n",
            "584    0.822354\n",
            "135    0.676365\n",
            "538    0.790915\n",
            "268    0.854527\n",
            "152    0.888328\n",
            "Name: NUM_TRIPS, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOENBOn-vitN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A scale is not required here, but the constant will be useful in the assignment.\n",
        "SCALE_NUM_TRIPS = 1.0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cri9VadSvm0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split our data into a training set i.e. 80% of the length of the shuffle array\n",
        "trainsize = int(len(shuffle['NUM_TRIPS'])*0.8)\n",
        "# The test set size is 100% - 80% = 20% of the length of the shuffle array.\n",
        "testsize = len(shuffle['NUM_TRIPS']) - trainsize\n",
        "\n",
        "# Define the number of input values (predictors)\n",
        "nppredictors = 22\n",
        "# Define the number of output values (targets)\n",
        "noutputs = 1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo7CEhVHvukm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c56610be-e761-4a2b-abd9-2065e6c9bfa1"
      },
      "source": [
        "# import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# needed for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_house_regression_trained_model', ignore_errors=True)\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_house_regression_trained_model', hidden_units=[20,18,14], optimizer=tf.train.AdamOptimizer(learning_rate=0.01), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "# Prints a log to show model is starting to train\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_NUM_TRIPS, steps=10000)\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores']*SCALE_NUM_TRIPS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# i.e. take the difference between the actual and the forecast then square the difference, \n",
        "# find the average of all the squares and then find the square root. \n",
        "# The RMSE essentially punishes larger errors i.e. it puts a heavier weight on larger errors.\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "\n",
        "# Calculate the mean of the Life Satisfaction Values.\n",
        "avg = np.mean(shuffle['NUM_TRIPS'][:trainsize])\n",
        "\n",
        "# Calculate the RMSE using Life Satisfaction Values and the mean of all target values.\n",
        "# The fit of a proposed regression model should therefore be better than the fit of the mean model.\n",
        "# In this case, it doesn't seem to be the case but it will vary on every run.\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_TRIPS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f079970d2e8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_house_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "starting to train\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_house_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 83719.58, step = 1\n",
            "INFO:tensorflow:global_step/sec: 484.759\n",
            "INFO:tensorflow:loss = 0.27201933, step = 101 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.788\n",
            "INFO:tensorflow:loss = 0.051235735, step = 201 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 608.368\n",
            "INFO:tensorflow:loss = 0.04089369, step = 301 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 605.135\n",
            "INFO:tensorflow:loss = 0.0486316, step = 401 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 647.952\n",
            "INFO:tensorflow:loss = 0.03325022, step = 501 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 611.703\n",
            "INFO:tensorflow:loss = 0.032885596, step = 601 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 645.78\n",
            "INFO:tensorflow:loss = 0.029932402, step = 701 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 677.504\n",
            "INFO:tensorflow:loss = 0.021729203, step = 801 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 664.736\n",
            "INFO:tensorflow:loss = 0.016356774, step = 901 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 552.738\n",
            "INFO:tensorflow:loss = 0.015090395, step = 1001 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 655.747\n",
            "INFO:tensorflow:loss = 0.011262998, step = 1101 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 574.858\n",
            "INFO:tensorflow:loss = 0.009420857, step = 1201 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 672.982\n",
            "INFO:tensorflow:loss = 0.009513003, step = 1301 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 627.835\n",
            "INFO:tensorflow:loss = 0.008842552, step = 1401 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 655.769\n",
            "INFO:tensorflow:loss = 0.0076188063, step = 1501 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 645.468\n",
            "INFO:tensorflow:loss = 0.0070250295, step = 1601 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 612.288\n",
            "INFO:tensorflow:loss = 0.005323823, step = 1701 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 591.675\n",
            "INFO:tensorflow:loss = 0.005623358, step = 1801 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.635\n",
            "INFO:tensorflow:loss = 0.004641922, step = 1901 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 648.308\n",
            "INFO:tensorflow:loss = 0.0058064833, step = 2001 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 656.334\n",
            "INFO:tensorflow:loss = 0.005761465, step = 2101 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 602.781\n",
            "INFO:tensorflow:loss = 0.004035086, step = 2201 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 604.111\n",
            "INFO:tensorflow:loss = 0.004403974, step = 2301 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 688.201\n",
            "INFO:tensorflow:loss = 0.002515541, step = 2401 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 672.76\n",
            "INFO:tensorflow:loss = 0.00372398, step = 2501 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.679\n",
            "INFO:tensorflow:loss = 0.0045407126, step = 2601 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 657.524\n",
            "INFO:tensorflow:loss = 0.0034570908, step = 2701 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.059\n",
            "INFO:tensorflow:loss = 0.00399203, step = 2801 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.291\n",
            "INFO:tensorflow:loss = 0.0031097312, step = 2901 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.639\n",
            "INFO:tensorflow:loss = 0.003914467, step = 3001 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 640.373\n",
            "INFO:tensorflow:loss = 0.0028536648, step = 3101 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 640.946\n",
            "INFO:tensorflow:loss = 0.003305242, step = 3201 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.14\n",
            "INFO:tensorflow:loss = 0.002517899, step = 3301 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 661.645\n",
            "INFO:tensorflow:loss = 0.002782104, step = 3401 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 650.058\n",
            "INFO:tensorflow:loss = 0.0023388716, step = 3501 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 588.817\n",
            "INFO:tensorflow:loss = 0.0026489939, step = 3601 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 680.039\n",
            "INFO:tensorflow:loss = 0.0027583253, step = 3701 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.794\n",
            "INFO:tensorflow:loss = 0.0025838898, step = 3801 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.226\n",
            "INFO:tensorflow:loss = 0.00216715, step = 3901 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 622.816\n",
            "INFO:tensorflow:loss = 0.00249124, step = 4001 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.796\n",
            "INFO:tensorflow:loss = 0.0020463536, step = 4101 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 629.062\n",
            "INFO:tensorflow:loss = 0.0032021129, step = 4201 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.876\n",
            "INFO:tensorflow:loss = 0.0033052843, step = 4301 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 620.446\n",
            "INFO:tensorflow:loss = 0.0023648895, step = 4401 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 664.871\n",
            "INFO:tensorflow:loss = 0.005621851, step = 4501 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.215\n",
            "INFO:tensorflow:loss = 0.0021227077, step = 4601 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 687.121\n",
            "INFO:tensorflow:loss = 0.0031162354, step = 4701 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 615.61\n",
            "INFO:tensorflow:loss = 0.00234972, step = 4801 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 621.075\n",
            "INFO:tensorflow:loss = 0.00251696, step = 4901 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.67\n",
            "INFO:tensorflow:loss = 0.0025993173, step = 5001 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 589.018\n",
            "INFO:tensorflow:loss = 0.0035347375, step = 5101 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.712\n",
            "INFO:tensorflow:loss = 0.0023782947, step = 5201 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 596.37\n",
            "INFO:tensorflow:loss = 0.0025282654, step = 5301 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 663.92\n",
            "INFO:tensorflow:loss = 0.0025181454, step = 5401 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 683.325\n",
            "INFO:tensorflow:loss = 0.027056575, step = 5501 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 689.599\n",
            "INFO:tensorflow:loss = 0.008068245, step = 5601 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 688.13\n",
            "INFO:tensorflow:loss = 0.0059263436, step = 5701 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 659.155\n",
            "INFO:tensorflow:loss = 0.025355307, step = 5801 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 682.138\n",
            "INFO:tensorflow:loss = 0.026088385, step = 5901 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 676.495\n",
            "INFO:tensorflow:loss = 0.0061774314, step = 6001 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.397\n",
            "INFO:tensorflow:loss = 0.0030290284, step = 6101 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 635.191\n",
            "INFO:tensorflow:loss = 0.030488543, step = 6201 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 660.887\n",
            "INFO:tensorflow:loss = 0.032073572, step = 6301 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 670.169\n",
            "INFO:tensorflow:loss = 0.0073480504, step = 6401 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 661.858\n",
            "INFO:tensorflow:loss = 0.08116819, step = 6501 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 669.437\n",
            "INFO:tensorflow:loss = 0.090198, step = 6601 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 675.918\n",
            "INFO:tensorflow:loss = 0.41863483, step = 6701 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 650.728\n",
            "INFO:tensorflow:loss = 0.07053977, step = 6801 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 625.39\n",
            "INFO:tensorflow:loss = 0.00308782, step = 6901 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 650.852\n",
            "INFO:tensorflow:loss = 0.010674475, step = 7001 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 611.971\n",
            "INFO:tensorflow:loss = 0.004008593, step = 7101 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.357\n",
            "INFO:tensorflow:loss = 0.005528483, step = 7201 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 650.485\n",
            "INFO:tensorflow:loss = 0.024798345, step = 7301 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.636\n",
            "INFO:tensorflow:loss = 0.0025076903, step = 7401 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 634.42\n",
            "INFO:tensorflow:loss = 0.021853272, step = 7501 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 624.184\n",
            "INFO:tensorflow:loss = 0.25458196, step = 7601 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 651.727\n",
            "INFO:tensorflow:loss = 0.022202717, step = 7701 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 629.761\n",
            "INFO:tensorflow:loss = 0.003289454, step = 7801 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 647.565\n",
            "INFO:tensorflow:loss = 0.01001472, step = 7901 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 652.779\n",
            "INFO:tensorflow:loss = 0.008649949, step = 8001 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 641.094\n",
            "INFO:tensorflow:loss = 0.0035960232, step = 8101 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 650.417\n",
            "INFO:tensorflow:loss = 0.34654218, step = 8201 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.236\n",
            "INFO:tensorflow:loss = 0.0026942259, step = 8301 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.158\n",
            "INFO:tensorflow:loss = 0.002846308, step = 8401 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.484\n",
            "INFO:tensorflow:loss = 0.0033668848, step = 8501 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 597.581\n",
            "INFO:tensorflow:loss = 0.0049378593, step = 8601 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 568.6\n",
            "INFO:tensorflow:loss = 0.008675877, step = 8701 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 642.283\n",
            "INFO:tensorflow:loss = 0.002516495, step = 8801 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 657.481\n",
            "INFO:tensorflow:loss = 0.0052106604, step = 8901 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 619.176\n",
            "INFO:tensorflow:loss = 0.013801547, step = 9001 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 651.169\n",
            "INFO:tensorflow:loss = 0.010561576, step = 9101 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.427\n",
            "INFO:tensorflow:loss = 0.0037716706, step = 9201 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.563\n",
            "INFO:tensorflow:loss = 0.0017527951, step = 9301 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 624.762\n",
            "INFO:tensorflow:loss = 0.0032535463, step = 9401 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 591.857\n",
            "INFO:tensorflow:loss = 0.0045582587, step = 9501 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 621.999\n",
            "INFO:tensorflow:loss = 0.0025541345, step = 9601 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 645.67\n",
            "INFO:tensorflow:loss = 0.005167993, step = 9701 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 657.265\n",
            "INFO:tensorflow:loss = 0.0020652532, step = 9801 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 662.165\n",
            "INFO:tensorflow:loss = 0.007009277, step = 9901 (0.154 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_house_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.007590425.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_house_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "DNNRegression has RMSE of 0.05651949513862127\n",
            "Just using average = 0.8215088256384095 has RMSE of 0.07391177619451002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KxRETghymhV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "a9c95998-9e4d-4862-e38b-23574f4e9a70"
      },
      "source": [
        "#\"Apr\",\"Aug\",\"Dec\",\"Feb\",\"Jan\",\"Jul\",\"Jun\",\"Mar\",\"May\",\"Nov\",\"Oct\",\"Sep\",\"Fri\",\"Mon\",\"Sat\",\"Sun\",\"Thu\",\"Tue\",\"Wed\",\"year\",\"temp\",\"wdsp\",\"NUM_TRIPS\"\n",
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "         'Apr' : [0,0,0],\n",
        "         'Aug' : [1,0,0],\n",
        "         'Dec' : [0,1,0],\n",
        "         'Feb' : [0,0,1],\n",
        "         'Jan' : [0,0,0],\n",
        "         'Jul' : [0,0,0],\n",
        "         'Jun' : [0,0,0],\n",
        "         'Mar' : [0,0,0],\n",
        "         'May' : [0,0,0],\n",
        "         'Nov' : [0,0,0],\n",
        "         'Oct' : [0,0,0],\n",
        "         'Sep' : [0,0,0],\n",
        "         'Fri' : [0,0,0],\n",
        "         'Mon' : [1,1,1],\n",
        "         'Sat' : [0,0,0],\n",
        "         'Sun' : [0,0,0],\n",
        "         'Thu' : [0,0,0],\n",
        "         'Tue' : [0,0,0],\n",
        "         'Wed' : [0,0,0],\n",
        "         'year' : [2009,2009,2009],\n",
        "         'temp' : [61.8, 31.2, 40.0],\n",
        "         'wdsp' : [5.0, 3.0, 8.0]\n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_house_regression_trained_model', hidden_units=[20,18,14], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "\n",
        "preds = estimator.predict(x=input.values)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0799261ac8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_house_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_house_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[0.6686224  0.7491697  0.73682344]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lalzD8Gb2S6G",
        "colab_type": "text"
      },
      "source": [
        "For the first, you can see below, we are in August, Saturday (we have a monday), 2009. We have a lower temperature and lower windspeed. The difference in day is likely to account for the higher actual number of trips.\n",
        "\n",
        "205\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t2009\t64.9\t4.2\t0.700748221591537\n",
        "\n",
        "For second (December):\n",
        "\n",
        "337\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t2009\t35.2\t6.6\t0.62902717790116\n",
        "\n",
        "For third (February):\n",
        "\n",
        "28\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t2009\t38.1\t3.6\t0.675798566550843\n",
        "\n",
        "The results overall look reasonable. You can look into this further. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbvoHSqq33ut",
        "colab_type": "text"
      },
      "source": [
        "Considerations for Assignment. I would likely use another method to either standardise or normalise num_trips. And perhaps not bother and scale them in here with SCALE_NUM_TRIPS with a generally large number.\n",
        "\n",
        "Obviously, you will likely want to have a number of variations but there is no reason you can't use most of the data given. Remember, the DNN is trying to solve a complex relationship, not a linear one. \n",
        "\n",
        "Other things to consider when doing this would be to take validation. Of course, in the assignment you will have a much larger range of data i.e. from some date x to y.\n",
        "\n",
        "This will give you more data. Taking real validation data that hasn't been shown to the model will give real results for you to check against rather than what I have done here (which is just for information)."
      ]
    }
  ]
}