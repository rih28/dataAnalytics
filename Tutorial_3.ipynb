{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial 3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZ6MVgSwXx3IGvoakB2CFX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rih28/dataAnalytics/blob/master/Tutorial_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w9sEQx-NFJv",
        "colab_type": "text"
      },
      "source": [
        "In this tutorial we will train and test a linear regressor. This is something you have already done in part 3 of the course document. So, I will miss out all of the extra notes and just get to business."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p-7cPGENClE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# needed to create the data frame\n",
        "import pandas as pd\n",
        "\n",
        "# create data frame from csv file we hosted on our github\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/rih28/dataAnalytics/master/tutorial2lineardata.csv', index_col=0, )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEw-Y4JWNkh1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d9260ab6-865e-462c-de60-5b3ea18e6762"
      },
      "source": [
        "# make sure we have our data by printing it out\n",
        "print(df[:6])\n",
        "# print(df) #all"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    day  temp  wdsp  NUM_TRIPS\n",
            "2     6  20.0   7.4   0.631126\n",
            "3     7  30.0  10.8   0.724951\n",
            "6     3  30.4   5.7   0.716044\n",
            "8     5  37.9  16.4   0.799994\n",
            "9     6  25.7  13.8   0.872611\n",
            "10    7  21.6   6.9   0.809792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4FV9fPUOkvw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "522ce8c0-c365-4c52-a318-26442b48ba96"
      },
      "source": [
        "# needed to help with speedy maths based calculations\n",
        "import numpy as np\n",
        "\n",
        "# iloc allows us to select by rows. Here, we are shuffling the data by rows determined at random.\n",
        "shuffle = df.iloc[np.random.permutation(len(df))]\n",
        "\n",
        "# we are selecting all rows of the columns outliined i.e. The 3rd (2 as indexes start from 0)\n",
        "predictors = shuffle.iloc[:,0:3]\n",
        "# Since it is the last column, we can also use\n",
        "# predictorTest = shuffle.iloc[:,-1]\n",
        "\n",
        "# print out the first 6 rows of predictors.\n",
        "print(predictors[:6])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      day  temp  wdsp\n",
            "191     6  61.0   3.6\n",
            "924     4  81.2   5.0\n",
            "1087    6  47.4   4.9\n",
            "741     3  27.2   4.8\n",
            "994     4  67.6   1.5\n",
            "98      4  43.1  12.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-gahQCyO6BJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f956d200-81db-4cfe-df8c-3dc7909b670c"
      },
      "source": [
        "# print out the shuffled data (first 5 rows)\n",
        "shuffle[:5]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>day</th>\n",
              "      <th>temp</th>\n",
              "      <th>wdsp</th>\n",
              "      <th>NUM_TRIPS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>6</td>\n",
              "      <td>61.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.806221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>924</th>\n",
              "      <td>4</td>\n",
              "      <td>81.2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.856447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1087</th>\n",
              "      <td>6</td>\n",
              "      <td>47.4</td>\n",
              "      <td>4.9</td>\n",
              "      <td>0.799774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>741</th>\n",
              "      <td>3</td>\n",
              "      <td>27.2</td>\n",
              "      <td>4.8</td>\n",
              "      <td>0.795774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>994</th>\n",
              "      <td>4</td>\n",
              "      <td>67.6</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.782085</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      day  temp  wdsp  NUM_TRIPS\n",
              "191     6  61.0   3.6   0.806221\n",
              "924     4  81.2   5.0   0.856447\n",
              "1087    6  47.4   4.9   0.799774\n",
              "741     3  27.2   4.8   0.795774\n",
              "994     4  67.6   1.5   0.782085"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hceMJGRGPPbl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "116d3130-6237-4f15-c029-ccb2a8f73558"
      },
      "source": [
        "# Select all rows for the 2nd column (i.e. 1)\n",
        "targets = shuffle.iloc[:,3]\n",
        "\n",
        "# print out the first 6 rows of the targets data.\n",
        "print(targets[:6])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "191     0.806221\n",
            "924     0.856447\n",
            "1087    0.799774\n",
            "741     0.795774\n",
            "994     0.782085\n",
            "98      0.814555\n",
            "Name: NUM_TRIPS, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTMxwMfGPdWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A scale is not required here, but the constant will be useful in the assignment.\n",
        "SCALE_NUM_TRIPS = 1.0"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbgNNZYkPkCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split our data into a training set i.e. 80% of the length of the shuffle array\n",
        "trainsize = int(len(shuffle['NUM_TRIPS'])*0.8)\n",
        "# The test set size is 100% - 80% = 20% of the length of the shuffle array.\n",
        "testsize = len(shuffle['NUM_TRIPS']) - trainsize\n",
        "\n",
        "# Define the number of input values (predictors)\n",
        "nppredictors = 3\n",
        "# Define the number of output values (targets)\n",
        "noutputs = 1"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maFRZkDkQdpA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4ec0e1c4-2697-494a-91e6-dc84cf63d9e6"
      },
      "source": [
        "# import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# needed for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/linear_regression_trained_model', ignore_errors=True)\n",
        "\n",
        "# This is the core of our linear regressor\n",
        "\n",
        "# You can see that we save the model, use the the Adam optimization algorithm, which is an extension \n",
        "# to stochastic gradient descent that has recently seen broader adoption for deep learning applications \n",
        "# in computer vision and natural language processing and infer real valued columns from input which interprets \n",
        "# all inputs as dense, fixed-length float values.\n",
        "\n",
        "# See the link for more information\n",
        "# https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib/learn/LinearRegressor\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model', optimizer=tf.train.AdamOptimizer(learning_rate=0.1), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "# Prints a log to show model is starting to train\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_GDP, steps=10000)\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores']*SCALE_NUM_TRIPS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# i.e. take the difference between the actual and the forecast then square the difference, \n",
        "# find the average of all the squares and then find the square root. \n",
        "# The RMSE essentially punishes larger errors i.e. it puts a heavier weight on larger errors.\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "\n",
        "# Calculate the mean of the Life Satisfaction Values.\n",
        "avg = np.mean(shuffle['NUM_TRIPS'][:trainsize])\n",
        "\n",
        "# Calculate the RMSE using Life Satisfaction Values and the mean of all target values.\n",
        "# The fit of a proposed regression model should therefore be better than the fit of the mean model.\n",
        "# In this case, it doesn't seem to be the case but it will vary on every run.\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_TRIPS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4c44e74978>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "starting to train\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.67021126, step = 1\n",
            "INFO:tensorflow:global_step/sec: 796.302\n",
            "INFO:tensorflow:loss = 0.020842107, step = 101 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 939.092\n",
            "INFO:tensorflow:loss = 0.0092563005, step = 201 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 981.034\n",
            "INFO:tensorflow:loss = 0.0030487222, step = 301 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 960.054\n",
            "INFO:tensorflow:loss = 0.0032761134, step = 401 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 973.089\n",
            "INFO:tensorflow:loss = 0.004066042, step = 501 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1007.25\n",
            "INFO:tensorflow:loss = 0.0031902245, step = 601 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 970.403\n",
            "INFO:tensorflow:loss = 0.0056318482, step = 701 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 889.634\n",
            "INFO:tensorflow:loss = 0.0037020799, step = 801 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 983.12\n",
            "INFO:tensorflow:loss = 0.0030598708, step = 901 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 902.888\n",
            "INFO:tensorflow:loss = 0.0031229632, step = 1001 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 1004.02\n",
            "INFO:tensorflow:loss = 0.004352262, step = 1101 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 918.237\n",
            "INFO:tensorflow:loss = 0.0036084824, step = 1201 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 973.048\n",
            "INFO:tensorflow:loss = 0.008489967, step = 1301 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 970.133\n",
            "INFO:tensorflow:loss = 0.0033924568, step = 1401 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 939.757\n",
            "INFO:tensorflow:loss = 0.004938363, step = 1501 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 970.681\n",
            "INFO:tensorflow:loss = 0.0053356783, step = 1601 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 976.794\n",
            "INFO:tensorflow:loss = 0.011996434, step = 1701 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 984.872\n",
            "INFO:tensorflow:loss = 0.044305574, step = 1801 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 949.578\n",
            "INFO:tensorflow:loss = 0.029005742, step = 1901 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 947.063\n",
            "INFO:tensorflow:loss = 0.032092977, step = 2001 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 992.281\n",
            "INFO:tensorflow:loss = 0.0122415945, step = 2101 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 871.415\n",
            "INFO:tensorflow:loss = 0.03507903, step = 2201 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 963.853\n",
            "INFO:tensorflow:loss = 0.0037041076, step = 2301 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 984.484\n",
            "INFO:tensorflow:loss = 0.0077939425, step = 2401 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1024.34\n",
            "INFO:tensorflow:loss = 0.04695321, step = 2501 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 1015.9\n",
            "INFO:tensorflow:loss = 0.0038301474, step = 2601 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 979.376\n",
            "INFO:tensorflow:loss = 0.0058249123, step = 2701 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 960.868\n",
            "INFO:tensorflow:loss = 0.019070853, step = 2801 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 972.006\n",
            "INFO:tensorflow:loss = 0.31833497, step = 2901 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1005.23\n",
            "INFO:tensorflow:loss = 0.02653344, step = 3001 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 975.848\n",
            "INFO:tensorflow:loss = 0.006525883, step = 3101 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 945.283\n",
            "INFO:tensorflow:loss = 0.0097705275, step = 3201 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 929.731\n",
            "INFO:tensorflow:loss = 0.021333955, step = 3301 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 988.875\n",
            "INFO:tensorflow:loss = 0.0041117985, step = 3401 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1015.72\n",
            "INFO:tensorflow:loss = 0.032104947, step = 3501 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 1017.72\n",
            "INFO:tensorflow:loss = 0.033798292, step = 3601 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 960.756\n",
            "INFO:tensorflow:loss = 0.19552359, step = 3701 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 949.638\n",
            "INFO:tensorflow:loss = 0.010194033, step = 3801 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 983.973\n",
            "INFO:tensorflow:loss = 0.0052984203, step = 3901 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 948.491\n",
            "INFO:tensorflow:loss = 0.005127922, step = 4001 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 980.94\n",
            "INFO:tensorflow:loss = 0.0041499445, step = 4101 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1001.63\n",
            "INFO:tensorflow:loss = 0.011397296, step = 4201 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 932.526\n",
            "INFO:tensorflow:loss = 0.0056719016, step = 4301 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 990.561\n",
            "INFO:tensorflow:loss = 0.02299889, step = 4401 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 992.331\n",
            "INFO:tensorflow:loss = 0.0039861393, step = 4501 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1020.24\n",
            "INFO:tensorflow:loss = 0.1354823, step = 4601 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 939.153\n",
            "INFO:tensorflow:loss = 0.087286696, step = 4701 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 984.689\n",
            "INFO:tensorflow:loss = 0.01867232, step = 4801 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1021.06\n",
            "INFO:tensorflow:loss = 0.05193743, step = 4901 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 989.664\n",
            "INFO:tensorflow:loss = 0.11617029, step = 5001 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 977.244\n",
            "INFO:tensorflow:loss = 0.010336701, step = 5101 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1008.86\n",
            "INFO:tensorflow:loss = 0.054875635, step = 5201 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 996.12\n",
            "INFO:tensorflow:loss = 0.014099773, step = 5301 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 996.428\n",
            "INFO:tensorflow:loss = 0.0669945, step = 5401 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 983.007\n",
            "INFO:tensorflow:loss = 0.006261736, step = 5501 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1009.02\n",
            "INFO:tensorflow:loss = 0.0043747183, step = 5601 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 887.871\n",
            "INFO:tensorflow:loss = 0.0035348209, step = 5701 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 930.413\n",
            "INFO:tensorflow:loss = 0.032515526, step = 5801 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 978.092\n",
            "INFO:tensorflow:loss = 0.011336872, step = 5901 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1023.76\n",
            "INFO:tensorflow:loss = 0.018623918, step = 6001 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 970.012\n",
            "INFO:tensorflow:loss = 0.114144176, step = 6101 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 994.979\n",
            "INFO:tensorflow:loss = 0.026344638, step = 6201 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 978.058\n",
            "INFO:tensorflow:loss = 0.016642634, step = 6301 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1001.23\n",
            "INFO:tensorflow:loss = 0.10218315, step = 6401 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 921.003\n",
            "INFO:tensorflow:loss = 0.0043010325, step = 6501 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 978.254\n",
            "INFO:tensorflow:loss = 0.0215255, step = 6601 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 971.565\n",
            "INFO:tensorflow:loss = 0.014879873, step = 6701 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1006.84\n",
            "INFO:tensorflow:loss = 0.0042954907, step = 6801 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 999.901\n",
            "INFO:tensorflow:loss = 0.04870916, step = 6901 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 958.893\n",
            "INFO:tensorflow:loss = 0.0032420866, step = 7001 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 879.957\n",
            "INFO:tensorflow:loss = 0.04643866, step = 7101 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 948.204\n",
            "INFO:tensorflow:loss = 0.021013731, step = 7201 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 929.247\n",
            "INFO:tensorflow:loss = 0.11268178, step = 7301 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 949.638\n",
            "INFO:tensorflow:loss = 0.019203825, step = 7401 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 948.037\n",
            "INFO:tensorflow:loss = 0.00661989, step = 7501 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 922.904\n",
            "INFO:tensorflow:loss = 0.04630774, step = 7601 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 952.394\n",
            "INFO:tensorflow:loss = 0.026979987, step = 7701 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 1025.63\n",
            "INFO:tensorflow:loss = 0.011490773, step = 7801 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1000.56\n",
            "INFO:tensorflow:loss = 0.02862402, step = 7901 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 995.931\n",
            "INFO:tensorflow:loss = 0.05568063, step = 8001 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 926.408\n",
            "INFO:tensorflow:loss = 0.011007863, step = 8101 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 947.326\n",
            "INFO:tensorflow:loss = 0.0033595092, step = 8201 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 991.807\n",
            "INFO:tensorflow:loss = 0.008054452, step = 8301 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 942.502\n",
            "INFO:tensorflow:loss = 0.0033178618, step = 8401 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 991.259\n",
            "INFO:tensorflow:loss = 0.18779236, step = 8501 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 959.139\n",
            "INFO:tensorflow:loss = 0.011963014, step = 8601 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 946.943\n",
            "INFO:tensorflow:loss = 0.0077379937, step = 8701 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1006.01\n",
            "INFO:tensorflow:loss = 0.14579836, step = 8801 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 953.463\n",
            "INFO:tensorflow:loss = 0.006046596, step = 8901 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 823.515\n",
            "INFO:tensorflow:loss = 0.019836225, step = 9001 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 906.369\n",
            "INFO:tensorflow:loss = 0.0030591423, step = 9101 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 910.141\n",
            "INFO:tensorflow:loss = 0.0072540687, step = 9201 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 964.731\n",
            "INFO:tensorflow:loss = 0.005334466, step = 9301 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 958.998\n",
            "INFO:tensorflow:loss = 0.0126813995, step = 9401 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 973.366\n",
            "INFO:tensorflow:loss = 0.043399796, step = 9501 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 991.641\n",
            "INFO:tensorflow:loss = 0.0070956303, step = 9601 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 982.802\n",
            "INFO:tensorflow:loss = 0.13797717, step = 9701 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 998.026\n",
            "INFO:tensorflow:loss = 0.012069508, step = 9801 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1009.38\n",
            "INFO:tensorflow:loss = 0.07701245, step = 9901 (0.099 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.028191496.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "LinearRegression has RMSE of 0.17654484136992526\n",
            "Just using average = 0.8225513538597933 has RMSE of 0.07533444941033914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S646OaU0R8UQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "145b3ff1-b9f3-48ff-f4e4-dc108099a0e4"
      },
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'day' : [1,1,1],\n",
        "         'temp' : [61.8, 31.2, 77.0],\n",
        "         'wdsp' : [5.0, 3.0, 8.0]\n",
        "        })\n",
        "\t\t\t\t\t\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "\n",
        "preds = estimator.predict(x=input.values)\n",
        "# Assume number of trips scale value is 600000 when at a maximum, based on the analysis from Tutorial 2\n",
        "predslistnorm = preds['scores']\n",
        "predslistscale = preds['scores']*600000\n",
        "prednorm = format(str(predslistnorm))\n",
        "pred = format(str(predslistscale))\n",
        "print(prednorm)\n",
        "print(pred)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4c44cc4ba8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[0.5762802  0.6659365  0.52739275]\n",
            "[345768.10598373 399561.91778183 316435.6470108 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsPQDn93UoDK",
        "colab_type": "text"
      },
      "source": [
        "From test inputs we have used, the first element in the array here is similar to this actual data:\n",
        "\n",
        "\"165\",1,62.4,5.6,0.668458757342322\n",
        "\n",
        "We can see that the temperature is slightly higher in the test data (which means less trips, but slightly higher wind means more trips. So, the difference between (actual) 0.668 and (predicted) 0.576 (rounded to 3 significant figures) seems reasonable. \n",
        "\n",
        "Similarly with the second:\n",
        "\n",
        "\"389\",1,26.6,3.1,0.763954173062719, which has higher number of trips due to a lower temperature and also with a slightly higher wind speed.\n",
        "\n",
        "And with the third:\n",
        "\n",
        "\"571\",1,77.2,8.4,0.724652060408235\n",
        "\n",
        "The last prediction with the higher temperature seems to punish the values more. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqqseK8ZXoFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "b04cea3d-7ec6-4293-8f4e-eedda40a548c"
      },
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'day' : [6,6,6],\n",
        "         'temp' : [61.8, 31.2, 77.0],\n",
        "         'wdsp' : [5.0, 3.0, 8.0]\n",
        "        })\n",
        "\t\t\t\t\t\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "\n",
        "preds = estimator.predict(x=input.values)\n",
        "# Assume number of trips scale value is 600000 when at a maximum, based on the analysis from Tutorial 2\n",
        "predslistnorm = preds['scores']\n",
        "predslistscale = preds['scores']*600000\n",
        "prednorm = format(str(predslistnorm))\n",
        "pred = format(str(predslistscale))\n",
        "print(prednorm)\n",
        "print(pred)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4c44be69e8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[0.67668766 0.766344   0.6278002 ]\n",
            "[406012.59469986 459806.40649796 376680.13572693]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvHvR5o9Xus1",
        "colab_type": "text"
      },
      "source": [
        "This test uses day 6 (Friday) instead of day 1 (Sunday) which shows higher number of trips. The other values were left the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAXcF8Z7X4ra",
        "colab_type": "text"
      },
      "source": [
        "Things to think about for the assignment. Make a validation set i.e. 5% of the data (or maybe more). This should be used for this type of testing. My values are simply made up.\n",
        "\n",
        "You should also remember to use different models with different data. In this case, I would maybe take each input valuable separately and make a regression model for each, then different variations i.e. any 2.\n",
        "\n",
        "Remember, you need to write up your results in the assignment. "
      ]
    }
  ]
}